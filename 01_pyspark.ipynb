{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c886a1-cc34-46ec-a620-279c1b2cc0d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Question 1. **\n",
    ">\n",
    "![alt text](question_ss/01.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d0a508-bc41-492b-8208-b056870ac3a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, col, coalesce, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a3e36b-556e-4ac0-a706-5d319c40d5af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"seperate_hobbies\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66deeb10-65e4-4bb0-b2ab-b74af26632b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [('Alice', 'Badminton, Tennis'), ('Bob', 'Tennis, Cricket'), ('Julis', 'Cricket, Carrom')]\n",
    "columns = [\"Name\", \"Hobbies\"]\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a8041e-2472-42f8-9bf5-8d9a73ab5878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586614da-4e96-4553-8dd5-e24b2e86a450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"PYSPARK_PYTHON:\", os.environ.get(\"PYSPARK_PYTHON\"))\n",
    "print(\"PYSPARK_DRIVER_PYTHON:\", os.environ.get(\"PYSPARK_DRIVER_PYTHON\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b4c79f1-6405-4942-a236-0ba155d422c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# split by comma which convert Hobbies from str -> Array \n",
    "df.select( col(\"Name\"), split(col(\"Hobbies\"), \",\").alias(\"Hobbies\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "364fd1d1-63dd-4a1a-ae9a-1fdbb3f3ee02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# explode function convert array to multiple rows\n",
    "df.select( col(\"Name\"), explode(split(col(\"Hobbies\"), \",\")).alias(\"Hobbies\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4e599c-730d-4891-ad57-cc76b83a9e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![alt text](question_ss/02.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3fbacc8-f8a9-4123-a08f-54c2fe785080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [('Goa', '', 'Mumbai'), ('', 'Mumbai', None), (None, '', 'Pune')]\n",
    "columns = ['city1', 'city2', 'city3']\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45e745b-5378-40ea-a434-7f42d00c0c9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This creates a new column firstnotnull that contains the first non-empty value among city1, city2, and city3 for each row.\n",
    "# coalesce() Returns the first column that is not null.\n",
    "df1 = df.withColumn(\n",
    "    'firstnotnull', \n",
    "    coalesce(\n",
    "        when(df['city1']=='', None).otherwise(df['city1']), \n",
    "        when(df['city2']=='', None).otherwise(df['city2']),\n",
    "        when(df['city3']=='', None).otherwise(df['city3'])\n",
    "    )\n",
    ")\n",
    "df1.select('firstnotnull').show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860b910d-5217-4d20-beee-2001f4cbfa63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **3. Claculate the % Marks for each student. Each student subject is of 100 marks. Create a result by following the below condition.**\n",
    ">\n",
    "![alt text](question_ss/03.jpg \"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7149a94-853e-4564-b374-02b41c6f731b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Answer\n",
    ">\n",
    "![alt text](question_ss/03a.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8a0397-24e0-45ce-ae96-c0edf92a8490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data1 = [(1, \"Steve\"), (2, 'David'), (3, 'John'), (4, 'Shree'), (5, 'Helen')]\n",
    "data2 = [(1, 'SQL', 40), (1, 'PySpark', 100), (2, 'SQL', 70), (2, 'PySpark', 60), (3, 'SQL', 30), (3, 'PySpark', 20), (4, 'SQL', 50), (4, 'PySpark', 50), (5, 'SQL', 45), (5, 'PySpark', 45)]\n",
    "\n",
    "schema1 = ['Id', 'Name']\n",
    "schema2 = ['Id', 'Subject', 'Mark']\n",
    "\n",
    "df1 = spark.createDataFrame(data1, schema1)\n",
    "df2 = spark.createDataFrame(data2, schema2)\n",
    "\n",
    "df1.show()\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef03fcab-d5bc-4ae2-a0b1-bea676b770fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: combine both tables or dataframes by using join\n",
    "df_join = df1.join(df2, df1['Id']==df2['Id']).drop(df2['Id'])\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07518c19-dead-4e6f-a67d-297fa23feb85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9642d144-4098-4b72-9c6f-f6c991fd020a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Calculating the percentage by groupby() on Id and Name column\n",
    "#  then sum of marks divided by total count\n",
    "df_per = df_join.groupBy('Id', 'Name').agg((sum(col('Mark'))/count('*')).alias('Percentage'))\n",
    "df_per.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1147d5fb-8687-40c0-888f-edcaba7c6122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: use when() and otherwise() to get Result\n",
    "result = df_per.select(\n",
    "    '*', \n",
    "    (\n",
    "        when(df_per['Percentage'] >=70, 'Distinction')\n",
    "        .when((df_per['Percentage'] < 70) & (df_per['Percentage'] >= 60), 'First Class')\n",
    "        .when((df_per['Percentage'] < 60) & (df_per['Percentage'] >= 50), 'Second Class')\n",
    "        .when((df_per['Percentage'] < 50) & (df_per['Percentage'] >= 40), 'Third Class')\n",
    "        .when(df_per['Percentage'] < 40, 'Fail')\n",
    "    ).alias('Result')\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ccfd2c-846d-438f-b8d3-bcc198ae90d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **3. Department wise nth highest salary employees.**\n",
    ">\n",
    "![alt text](question_ss/04.jpg \"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252e16c4-f402-4e47-8dec-d9d3a698dee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Answer\n",
    ">\n",
    "![alt text](question_ss/04a.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e1286c2-7677-4844-88e3-82e5783f3d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data1=[(1,\"A\",1000,\"IT\"),(2,\"B\",1500,\"IT\"),(3,\"C\",2500,\"IT\"),(4,\"D\",3000,\"HR\"),(5,\"E\",2000,\"HR\"),(6,\"F\",1000,\"HR\")\n",
    "       ,(7,\"G\",4000,\"Sales\"),(8,\"H\",4000,\"Sales\"),(9,\"I\",1000,\"Sales\"),(10,\"J\",2000,\"Sales\")]\n",
    "schema1=[\"EmpId\",\"EmpName\",\"Salary\",\"DeptName\"]\n",
    "df=spark.createDataFrame(data1,schema1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea87fd0-3083-4e2d-af3f-e485987e3100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7857a750-3eec-46b3-a62c-41f9bd15b47a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_rank = df.select(\n",
    "    '*',\n",
    "    dense_rank().over(\n",
    "        Window.partitionBy(df['DeptName'])\n",
    "        .orderBy(df['Salary'].desc())\n",
    "    ).alias('rank')\n",
    ")\n",
    "\n",
    "df_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8a44e3e-100a-47ad-b0a9-40777b06d81c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "res = df_rank.filter(df_rank.rank==1)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ca7863e-a9a0-478a-ab2a-b9573d846583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **5.**\n",
    ">\n",
    "![alt text](question_ss/05.jpg \"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e7ce5f2-0310-4778-a762-2d13dff9312d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Answer\n",
    ">\n",
    "![alt text](question_ss/05a.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e15b6e8-8d75-42f6-a800-ac3212768fa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Employees Salary info\n",
    "data1=[(100,\"Raj\",None,1,\"01-04-23\",50000), (200,\"Joanne\",100,1,\"01-04-23\",4000),\n",
    "       (200,\"Joanne\",100,1,\"13-04-23\",4500),(200,\"Joanne\",100,1,\"14-04-23\",4020)]\n",
    "\n",
    "schema1=[\"EmpId\",\"EmpName\",\"Mgrid\",\"deptid\",\"salarydt\",\"salary\"]\n",
    "\n",
    "df_salary=spark.createDataFrame(data1,schema1)\n",
    "df_salary.show()\n",
    "\n",
    "#department dataframe\n",
    "data2=[(1,\"IT\"), (2,\"HR\")]\n",
    "schema2=[\"deptid\",\"deptname\"]\n",
    "\n",
    "df_dept=spark.createDataFrame(data2,schema2)\n",
    "df_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30247622-2980-42cc-a506-a270583a2ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reformat date column \n",
    "df = df_salary.withColumn('Newsaldt', to_date(col('salarydt'), 'dd-MM-yy'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b10b27-d44c-479d-b19d-c4dfecd3c46d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# join both df, join with only ['deptid] so that it will remove duplicate deptid col\n",
    "df_join = df.join(df_dept, ['deptid'])\n",
    "\n",
    "# Self join to get manager details\n",
    "df_joined = df_join.alias('tbl1').join(\n",
    "\tdf_join.alias('tbl2'),\n",
    "\tcol('tbl1.Mgrid') == col('tbl2.EmpId'),\n",
    "\t'left'\n",
    ").select(\n",
    "    col('tbl1.deptname'),\n",
    "\tcol('tbl2.EmpName').alias('ManagerName'),\n",
    "\tcol('tbl1.EmpName').alias('EmpName'),\n",
    "\tcol('tbl1.Newsaldt').alias('Newsaldt'),\n",
    "\tcol('tbl1.salary').alias('salary'),\n",
    ")\n",
    "\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f5b8d0-bf58-4201-94e6-fc3190ef2293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# groupby\n",
    "res = df_joined.groupBy('deptname', 'ManagerName', 'EmpName', year('Newsaldt').alias('Year'), date_format('Newsaldt', 'MMM').alias('Month')).sum('salary')\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3f7269-f529-4052-93ee-8e76b09fe1e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **6. How to check data skew Issue and how to solve it.**\n",
    ">\n",
    "![alt text](question_ss/06.jpg \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc5fbe8-16d4-4dc1-959e-f73ce33db9aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2084b625-9de3-4eea-b21a-2bd210370831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **6. Merger two dataframes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ec15fe0-7836-4558-88e2-8e5408acdb43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "simpleData = [(1, \"Sagar\", \"CSE\", \"UP\", 80), (2, \"Shivam\", \"IT\", \"MP\", 86), (3, \"Muni\", \"Mech\", \"AP\", 70)]\n",
    "\n",
    "simpleData_2 = [(5, \"Raj\", \"CSE\", \"HP\"), (7, \"Kunal\", \"Mech\", \"Rajasthan\")]\n",
    "\n",
    "\n",
    "columns_1 = [\"ID\", \"Student_Name\", \"Department_Name\", \"City\", \"Marks\"]\n",
    "columns_2 = [\"ID\", \"Student_Name\", \"Department_Name\", \"City\"]\n",
    "\n",
    "df_1 = spark.createDataFrame(data = simpleData, schema = columns_1)\n",
    "df_2 = spark.createDataFrame(data = simpleData_2, schema = columns_2)\n",
    "df_1.show()\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ab47e6-eed6-4cad-8853-abb1f0aec85d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_1.unionByName(df_2, allowMissingColumns=True)\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_pyspark",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "pyspark_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
